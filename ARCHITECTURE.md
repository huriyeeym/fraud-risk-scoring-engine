# ðŸ›ï¸ System Architecture - Fraud & Risk Scoring Engine

## ðŸ“‹ Table of Contents
- [Design Principles](#design-principles)
- [Microservices Architecture](#microservices-architecture)
- [Data Flow](#data-flow)
- [Technology Decisions](#technology-decisions)
- [Scalability Considerations](#scalability-considerations)

---

## ðŸŽ¯ Design Principles

### 1. **Event-Driven Architecture**
**Why?**
- Banking transactions happen in **bursts** (rush hours)
- Need to **decouple** services for resilience
- **Async processing** prevents bottlenecks

**How?**
- Kafka as message broker
- Services communicate via events
- No direct HTTP calls between services

### 2. **Hybrid Fraud Detection**
**Why Pure Rules Don't Work:**
- Too rigid â†’ Many false positives
- Hard to maintain â†’ 100+ rules become chaos

**Why Pure ML Doesn't Work:**
- "Black box" â†’ No explanation
- Regulators demand transparency
- Need instant updates (no retraining delay)

**Our Solution: Hybrid**
```
Final Score = (Rule Score Ã— 0.6) + (ML Score Ã— 0.4)
            â†“                      â†“
      Explainable            Adaptive Learning
```

### 3. **Microservices (Not Monolith)**
**Why?**
- **Independent scaling** â†’ ML service needs GPU, others don't
- **Technology diversity** â†’ Java for business logic, Python for ML
- **Team autonomy** â†’ Different teams own different services
- **Fault isolation** â†’ If dashboard crashes, fraud detection still works

---

## ðŸ§© Microservices Architecture

### **Service Breakdown**

| Service | Responsibility | Technology | Why This Tech? |
|---------|---------------|------------|----------------|
| **Transaction Service** | Receive transactions, publish to Kafka | Spring Boot | Excellent Kafka integration, high throughput |
| **Risk Engine Service** | Apply rules, calculate risk score | Spring Boot | Complex business logic, need strong typing |
| **ML Service** | Fraud probability prediction | Python (FastAPI) | ML libraries (scikit-learn, TensorFlow) |
| **Alert Service** | Manage high-risk alerts | Spring Boot | Integration with email/SMS providers |
| **Customer Profile Service** | Build behavioral profiles | Spring Boot | Aggregate data, complex queries |
| **Dashboard** | Real-time visualization | React | Modern UI, WebSocket support |

---

## ðŸ”„ Data Flow

### **Transaction Processing Flow**

```
1. Transaction Arrives
   â†“
[Transaction Service]
   â”‚
   â”‚ Validation
   â”‚ âœ“ Required fields exist?
   â”‚ âœ“ Amount > 0?
   â”‚ âœ“ Valid customer_id?
   â”‚
   â”œâ”€â†’ [PostgreSQL] (store original transaction)
   â””â”€â†’ [Kafka Topic: transactions-raw]
          â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Risk Engine Service          â”‚
      â”‚  (Consumes from Kafka)        â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€â†’ Apply Rules (Parallel)
          â”‚   â”œâ”€ Velocity Check
          â”‚   â”œâ”€ Amount Threshold
          â”‚   â”œâ”€ Location Anomaly
          â”‚   â””â”€ Merchant Category Risk
          â”‚
          â”œâ”€â†’ Call ML Service (HTTP)
          â”‚   â””â”€ Get fraud probability (0-1)
          â”‚
          â”œâ”€â†’ Fetch Customer Profile (Redis Cache)
          â”‚   â””â”€ Compare with historical behavior
          â”‚
          â””â”€â†’ Calculate Final Score
              â”‚
              â”œâ”€â†’ [PostgreSQL] (store risk_scores)
              â”‚
              â””â”€â†’ If score > 70:
                  [Kafka Topic: fraud-alerts]
                      â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Alert Service  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”œâ”€â†’ Send to Dashboard (WebSocket)
                      â”œâ”€â†’ Store in alerts table
                      â””â”€â†’ (Future: Email/SMS)
```

### **Why This Flow?**

**Step 1: Kafka (Not Direct HTTP)**
- âŒ `API Gateway â†’ Risk Engine` = Tight coupling
- âœ… `API Gateway â†’ Kafka â†’ Risk Engine` = Loose coupling
- If Risk Engine is down, transactions still get queued

**Step 2: Parallel Rule Execution**
- Rules run concurrently (Java Streams API)
- 10 rules in 50ms instead of 500ms

**Step 3: Redis Cache for Profiles**
- âŒ `PostgreSQL lookup every time` = 100ms
- âœ… `Redis cache` = 2ms
- Profiles updated async (hourly batch job)

---

## ðŸ§  Rule Engine Design

### **Rule Interface**
```java
public interface FraudRule {
    int calculateScore(Transaction transaction, CustomerProfile profile);
    String getReason();
    int getPriority(); // Higher priority rules run first
}
```

### **Example Rules**

#### **1. High Amount Rule**
```java
if (transaction.amount > profile.avgAmount * 3) {
    score += 30;
    reason = "Amount is 3x customer average";
}
```

#### **2. Velocity Rule**
```java
int transactionsLast10Min = countRecentTransactions(customerId, 10_MINUTES);
if (transactionsLast10Min > 5) {
    score += 40;
    reason = "5+ transactions in 10 minutes";
}
```

#### **3. Location Anomaly**
```java
if (!profile.frequentLocations.contains(transaction.location)) {
    score += 25;
    reason = "Unusual location: " + transaction.location;
}
```

### **Why This Design?**
- âœ… **Extensible**: Add new rules without changing core engine
- âœ… **Testable**: Each rule is isolated, easy to unit test
- âœ… **Explainable**: Each rule provides a reason
- âœ… **Prioritizable**: Critical rules run first

---

## ðŸ¤– ML Model Architecture

### **Model Choice: Logistic Regression (v1)**

**Why Not Deep Learning?**
- Logistic Regression:
  - âœ… Fast inference (<10ms)
  - âœ… Explainable (feature weights)
  - âœ… Works well with small datasets
- Deep Learning:
  - âŒ Needs millions of samples
  - âŒ Black box
  - âŒ Overkill for this problem

**Future**: Upgrade to Random Forest if accuracy isn't enough

### **Feature Engineering**
```python
features = [
    'amount',
    'amount_zscore',  # (amount - mean) / std
    'hour_of_day',
    'is_weekend',
    'merchant_category_encoded',
    'location_risk_score',
    'days_since_first_transaction',
    'avg_amount_last_30_days',
    'transaction_count_last_hour'
]
```

### **Training Pipeline**
```python
1. Fetch labeled data (PostgreSQL)
   â””â”€ fraud_transactions table (is_fraud: true/false)

2. Feature engineering
   â””â”€ Calculate derived features

3. Train model
   â””â”€ 80% train, 20% test

4. Evaluate
   â””â”€ Precision, Recall, F1-Score

5. Save model
   â””â”€ model.pkl â†’ loaded by ML service

6. (Future) A/B Testing
   â””â”€ Deploy v2 model to 10% of traffic
```

---

## ðŸ“Š Database Schema Design

### **Why PostgreSQL?**
- âœ… ACID transactions (consistency is critical)
- âœ… JSONB support (flexible `reasons` field)
- âœ… Excellent query performance with indexes

### **Why Redis?**
- âœ… Sub-millisecond reads
- âœ… Perfect for customer profiles (read-heavy)
- âœ… TTL support (auto-expire old data)

### **Schema**

#### **transactions**
```sql
CREATE TABLE transactions (
    transaction_id VARCHAR(50) PRIMARY KEY,
    customer_id VARCHAR(50) NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    merchant_category VARCHAR(100),
    location VARCHAR(100),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_customer_timestamp (customer_id, timestamp),
    INDEX idx_timestamp (timestamp)
);
```
**Why these indexes?**
- `idx_customer_timestamp`: Velocity rules (recent transactions per customer)
- `idx_timestamp`: Daily trend queries

#### **risk_scores**
```sql
CREATE TABLE risk_scores (
    id SERIAL PRIMARY KEY,
    transaction_id VARCHAR(50) REFERENCES transactions(transaction_id),
    rule_score INT,
    ml_score DECIMAL(5,2),
    final_score DECIMAL(5,2),
    reasons JSONB,  -- {"high_amount": 30, "velocity": 40}
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_final_score (final_score DESC),
    INDEX idx_created_at (created_at)
);
```

#### **customer_profiles**
```sql
CREATE TABLE customer_profiles (
    customer_id VARCHAR(50) PRIMARY KEY,
    avg_amount DECIMAL(10,2),
    frequent_locations JSONB,  -- ["Istanbul", "Ankara"]
    merchant_categories JSONB,  -- {"electronics": 0.4, "food": 0.6}
    transaction_count INT,
    first_transaction_date DATE,
    last_updated TIMESTAMP
);
```

---

## âš¡ Scalability Considerations

### **Current (MVP) Throughput**
- ~1,000 transactions/second

### **Future Scaling Strategies**

#### **1. Horizontal Scaling**
```yaml
# docker-compose.yml
risk-engine-service:
  deploy:
    replicas: 5  # Run 5 instances
```
Kafka will distribute load across instances

#### **2. Database Partitioning**
```sql
-- Partition transactions by date
CREATE TABLE transactions_2025_01 PARTITION OF transactions
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

#### **3. Caching Strategy**
```
Redis (hot data, 1-hour TTL)
  â†“ (cache miss)
PostgreSQL (all data)
```

#### **4. Kafka Tuning**
```properties
# More partitions = more parallelism
num.partitions=12

# Batch processing
batch.size=16384
```

---

## ðŸ”’ Security Considerations

### **1. Sensitive Data**
- âŒ NEVER log full transaction details
- âœ… Log only `transaction_id` + `risk_score`

### **2. Environment Variables**
```bash
# .env (NEVER commit to Git!)
DB_PASSWORD=super_secret
KAFKA_PASSWORD=another_secret
```

### **3. API Authentication**
```java
@PreAuthorize("hasRole('FRAUD_ANALYST')")
public List<Alert> getHighRiskAlerts() { ... }
```

---

## ðŸ§ª Testing Strategy

### **Unit Tests**
- Each fraud rule tested independently
- Mock customer profiles
- Example:
  ```java
  @Test
  void testHighAmountRule() {
      Transaction tx = new Transaction(amount: 10000);
      CustomerProfile profile = new CustomerProfile(avgAmount: 1000);

      int score = highAmountRule.calculate(tx, profile);

      assertEquals(30, score);
  }
  ```

### **Integration Tests**
- End-to-end flow
- Real Kafka (Testcontainers)
- Example:
  ```java
  @Test
  void testFraudDetectionFlow() {
      // Send transaction to Kafka
      kafkaTemplate.send("transactions-raw", transaction);

      // Wait for processing
      await().atMost(5, SECONDS)
             .until(() -> alertRepository.findByTransactionId(txId) != null);

      // Verify alert was created
      Alert alert = alertRepository.findByTransactionId(txId);
      assertTrue(alert.getScore() > 70);
  }
  ```

---

## ðŸ“ˆ Monitoring & Observability

### **Metrics to Track**
```
- Transactions processed/second
- Average processing time per transaction
- Fraud detection rate (% of transactions flagged)
- False positive rate
- ML model accuracy (weekly)
- Kafka lag (messages waiting to be processed)
```

### **Tools**
- **Prometheus**: Metrics collection
- **Grafana**: Dashboards
- **ELK Stack**: Log aggregation

---

## ðŸ”® Future Enhancements

1. **Graph Database** (Neo4j)
   - Detect fraud rings (connected accounts)

2. **Stream Processing** (Kafka Streams)
   - Real-time aggregations

3. **Feature Store** (Feast)
   - Centralized feature management

4. **Model Monitoring**
   - Detect model drift
   - Auto-retrain when accuracy drops

---

**Last Updated**: 2025-01-07
**Version**: 1.0
